{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/train_preprocessed.csv\")\n",
    "train_x = train.drop([\"target\"], axis=1)\n",
    "train_y = train[\"target\"]\n",
    "\n",
    "test_x = pd.read_csv(\"../data/test_preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>product</th>\n",
       "      <th>amount</th>\n",
       "      <th>medical_info_a1</th>\n",
       "      <th>medical_info_a2</th>\n",
       "      <th>medical_info_a3</th>\n",
       "      <th>medical_info_b1</th>\n",
       "      <th>...</th>\n",
       "      <th>medical_keyword_6</th>\n",
       "      <th>medical_keyword_7</th>\n",
       "      <th>medical_keyword_8</th>\n",
       "      <th>medical_keyword_9</th>\n",
       "      <th>medical_keyword_10</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>yearmonth</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>166.445608</td>\n",
       "      <td>65.016732</td>\n",
       "      <td>9</td>\n",
       "      <td>7000000</td>\n",
       "      <td>134</td>\n",
       "      <td>202</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>24182</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>164.334615</td>\n",
       "      <td>56.544217</td>\n",
       "      <td>0</td>\n",
       "      <td>7000000</td>\n",
       "      <td>438</td>\n",
       "      <td>263</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>24185</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>167.462917</td>\n",
       "      <td>54.242267</td>\n",
       "      <td>2</td>\n",
       "      <td>6000000</td>\n",
       "      <td>313</td>\n",
       "      <td>325</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>24194</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>177.097725</td>\n",
       "      <td>71.147762</td>\n",
       "      <td>3</td>\n",
       "      <td>8000000</td>\n",
       "      <td>342</td>\n",
       "      <td>213</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>24187</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>158.165788</td>\n",
       "      <td>65.240697</td>\n",
       "      <td>1</td>\n",
       "      <td>9000000</td>\n",
       "      <td>327</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>24201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>182.729800</td>\n",
       "      <td>73.393777</td>\n",
       "      <td>1</td>\n",
       "      <td>2000000</td>\n",
       "      <td>189</td>\n",
       "      <td>232</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>24190</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>167.701136</td>\n",
       "      <td>75.006529</td>\n",
       "      <td>8</td>\n",
       "      <td>9000</td>\n",
       "      <td>426</td>\n",
       "      <td>202</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>24185</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>145.609998</td>\n",
       "      <td>47.739397</td>\n",
       "      <td>8</td>\n",
       "      <td>1000</td>\n",
       "      <td>370</td>\n",
       "      <td>274</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>24194</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>165.796017</td>\n",
       "      <td>57.567695</td>\n",
       "      <td>6</td>\n",
       "      <td>5000</td>\n",
       "      <td>291</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>24194</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>180.301762</td>\n",
       "      <td>71.425135</td>\n",
       "      <td>4</td>\n",
       "      <td>1000000</td>\n",
       "      <td>288</td>\n",
       "      <td>454</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>24187</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex      height     weight  product   amount  medical_info_a1  \\\n",
       "0      50    1  166.445608  65.016732        9  7000000              134   \n",
       "1      68    0  164.334615  56.544217        0  7000000              438   \n",
       "2      77    1  167.462917  54.242267        2  6000000              313   \n",
       "3      17    1  177.097725  71.147762        3  8000000              342   \n",
       "4      62    0  158.165788  65.240697        1  9000000              327   \n",
       "...   ...  ...         ...        ...      ...      ...              ...   \n",
       "9995   61    1  182.729800  73.393777        1  2000000              189   \n",
       "9996   33    0  167.701136  75.006529        8     9000              426   \n",
       "9997   44    0  145.609998  47.739397        8     1000              370   \n",
       "9998   34    0  165.796017  57.567695        6     5000              291   \n",
       "9999   31    1  180.301762  71.425135        4  1000000              288   \n",
       "\n",
       "      medical_info_a2  medical_info_a3  medical_info_b1  ...  \\\n",
       "0                 202                1               11  ...   \n",
       "1                 263                3               14  ...   \n",
       "2                 325                1               18  ...   \n",
       "3                 213                2               11  ...   \n",
       "4                 102                0               14  ...   \n",
       "...               ...              ...              ...  ...   \n",
       "9995              232                7               17  ...   \n",
       "9996              202                3               19  ...   \n",
       "9997              274                1               11  ...   \n",
       "9998              105                1               13  ...   \n",
       "9999              454                4               13  ...   \n",
       "\n",
       "      medical_keyword_6  medical_keyword_7  medical_keyword_8  \\\n",
       "0                     1                  0                  1   \n",
       "1                     0                  1                  1   \n",
       "2                     1                  0                  1   \n",
       "3                     0                  0                  1   \n",
       "4                     0                  1                  1   \n",
       "...                 ...                ...                ...   \n",
       "9995                  0                  0                  1   \n",
       "9996                  0                  0                  1   \n",
       "9997                  0                  0                  1   \n",
       "9998                  1                  1                  1   \n",
       "9999                  1                  0                  1   \n",
       "\n",
       "      medical_keyword_9  medical_keyword_10  year  month  day  yearmonth  \\\n",
       "0                     0                   0  2015      2    3      24182   \n",
       "1                     0                   0  2015      5    9      24185   \n",
       "2                     0                   0  2016      2   13      24194   \n",
       "3                     0                   0  2015      7    6      24187   \n",
       "4                     1                   0  2016      9   17      24201   \n",
       "...                 ...                 ...   ...    ...  ...        ...   \n",
       "9995                  1                   0  2015     10   21      24190   \n",
       "9996                  1                   0  2015      5   28      24185   \n",
       "9997                  0                   1  2016      2   29      24194   \n",
       "9998                  1                   0  2016      2   27      24194   \n",
       "9999                  0                   0  2015      7    1      24187   \n",
       "\n",
       "      target  \n",
       "0          0  \n",
       "1          0  \n",
       "2          1  \n",
       "3          0  \n",
       "4          1  \n",
       "...      ...  \n",
       "9995       0  \n",
       "9996       0  \n",
       "9997       0  \n",
       "9998       0  \n",
       "9999       0  \n",
       "\n",
       "[10000 rows x 29 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                      0\n",
       "sex                      0\n",
       "height                   0\n",
       "weight                   0\n",
       "product                  0\n",
       "amount                   0\n",
       "medical_info_a1          0\n",
       "medical_info_a2          0\n",
       "medical_info_a3          0\n",
       "medical_info_b1          0\n",
       "medical_info_b2          0\n",
       "medical_info_b3          0\n",
       "medical_info_c1       3001\n",
       "medical_info_c2       7981\n",
       "medical_keyword_1        0\n",
       "medical_keyword_2        0\n",
       "medical_keyword_3        0\n",
       "medical_keyword_4        0\n",
       "medical_keyword_5        0\n",
       "medical_keyword_6        0\n",
       "medical_keyword_7        0\n",
       "medical_keyword_8        0\n",
       "medical_keyword_9        0\n",
       "medical_keyword_10       0\n",
       "year                     0\n",
       "month                    0\n",
       "day                      0\n",
       "yearmonth                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, params=None):\n",
    "        self.model = None\n",
    "        if params is None:\n",
    "           self.params = {}\n",
    "        else:\n",
    "            self.params = params\n",
    "\n",
    "    def fit(self, tr_x, tr_y, va_x, va_y):\n",
    "        params = {'objective': 'binary', 'seed': 71, 'verbose': 0, 'metrics': 'binary_logloss'}\n",
    "        num_round = 100\n",
    "        params.update(self.params)\n",
    "\n",
    "        dtrain = lgb.Dataset(tr_x, tr_y)\n",
    "        dvalid = lgb.Dataset(va_x, va_y)\n",
    "\n",
    "        self.model = lgb.train(\n",
    "            params, dtrain, num_boost_round=num_round, valid_names=[\"train\", \"valid\"], valid_sets=[dtrain, dvalid]\n",
    "        )\n",
    "    def perdict(self, x):\n",
    "        pred = self.model.predict(x)\n",
    "        return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hold-out法での分割\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "tr_x, va_x, tr_y, va_y = train_test_split(train_x, train_y, test_size=0.25, random_state=71, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[1]\ttrain's binary_logloss: 0.454308\tvalid's binary_logloss: 0.465515\n",
      "[2]\ttrain's binary_logloss: 0.429565\tvalid's binary_logloss: 0.443444\n",
      "[3]\ttrain's binary_logloss: 0.410077\tvalid's binary_logloss: 0.425543\n",
      "[4]\ttrain's binary_logloss: 0.39358\tvalid's binary_logloss: 0.410625\n",
      "[5]\ttrain's binary_logloss: 0.379354\tvalid's binary_logloss: 0.397666\n",
      "[6]\ttrain's binary_logloss: 0.365913\tvalid's binary_logloss: 0.387422\n",
      "[7]\ttrain's binary_logloss: 0.354309\tvalid's binary_logloss: 0.376037\n",
      "[8]\ttrain's binary_logloss: 0.344354\tvalid's binary_logloss: 0.366734\n",
      "[9]\ttrain's binary_logloss: 0.334834\tvalid's binary_logloss: 0.35898\n",
      "[10]\ttrain's binary_logloss: 0.326209\tvalid's binary_logloss: 0.351612\n",
      "[11]\ttrain's binary_logloss: 0.317809\tvalid's binary_logloss: 0.34563\n",
      "[12]\ttrain's binary_logloss: 0.310845\tvalid's binary_logloss: 0.340564\n",
      "[13]\ttrain's binary_logloss: 0.30401\tvalid's binary_logloss: 0.334274\n",
      "[14]\ttrain's binary_logloss: 0.296333\tvalid's binary_logloss: 0.327911\n",
      "[15]\ttrain's binary_logloss: 0.290137\tvalid's binary_logloss: 0.324239\n",
      "[16]\ttrain's binary_logloss: 0.283293\tvalid's binary_logloss: 0.317865\n",
      "[17]\ttrain's binary_logloss: 0.277823\tvalid's binary_logloss: 0.314412\n",
      "[18]\ttrain's binary_logloss: 0.272322\tvalid's binary_logloss: 0.310773\n",
      "[19]\ttrain's binary_logloss: 0.26705\tvalid's binary_logloss: 0.307374\n",
      "[20]\ttrain's binary_logloss: 0.262091\tvalid's binary_logloss: 0.303946\n",
      "[21]\ttrain's binary_logloss: 0.257394\tvalid's binary_logloss: 0.301154\n",
      "[22]\ttrain's binary_logloss: 0.253115\tvalid's binary_logloss: 0.298085\n",
      "[23]\ttrain's binary_logloss: 0.24878\tvalid's binary_logloss: 0.294533\n",
      "[24]\ttrain's binary_logloss: 0.243951\tvalid's binary_logloss: 0.291832\n",
      "[25]\ttrain's binary_logloss: 0.240469\tvalid's binary_logloss: 0.289538\n",
      "[26]\ttrain's binary_logloss: 0.236038\tvalid's binary_logloss: 0.285777\n",
      "[27]\ttrain's binary_logloss: 0.231149\tvalid's binary_logloss: 0.281554\n",
      "[28]\ttrain's binary_logloss: 0.227936\tvalid's binary_logloss: 0.279469\n",
      "[29]\ttrain's binary_logloss: 0.224501\tvalid's binary_logloss: 0.278255\n",
      "[30]\ttrain's binary_logloss: 0.221476\tvalid's binary_logloss: 0.27687\n",
      "[31]\ttrain's binary_logloss: 0.218174\tvalid's binary_logloss: 0.274434\n",
      "[32]\ttrain's binary_logloss: 0.214462\tvalid's binary_logloss: 0.272274\n",
      "[33]\ttrain's binary_logloss: 0.21088\tvalid's binary_logloss: 0.269122\n",
      "[34]\ttrain's binary_logloss: 0.207684\tvalid's binary_logloss: 0.266756\n",
      "[35]\ttrain's binary_logloss: 0.205168\tvalid's binary_logloss: 0.265291\n",
      "[36]\ttrain's binary_logloss: 0.202792\tvalid's binary_logloss: 0.264635\n",
      "[37]\ttrain's binary_logloss: 0.200275\tvalid's binary_logloss: 0.263032\n",
      "[38]\ttrain's binary_logloss: 0.19745\tvalid's binary_logloss: 0.261202\n",
      "[39]\ttrain's binary_logloss: 0.194507\tvalid's binary_logloss: 0.25904\n",
      "[40]\ttrain's binary_logloss: 0.192425\tvalid's binary_logloss: 0.257587\n",
      "[41]\ttrain's binary_logloss: 0.190121\tvalid's binary_logloss: 0.256767\n",
      "[42]\ttrain's binary_logloss: 0.187834\tvalid's binary_logloss: 0.255625\n",
      "[43]\ttrain's binary_logloss: 0.184909\tvalid's binary_logloss: 0.254088\n",
      "[44]\ttrain's binary_logloss: 0.181938\tvalid's binary_logloss: 0.252355\n",
      "[45]\ttrain's binary_logloss: 0.180014\tvalid's binary_logloss: 0.251427\n",
      "[46]\ttrain's binary_logloss: 0.177952\tvalid's binary_logloss: 0.250039\n",
      "[47]\ttrain's binary_logloss: 0.175486\tvalid's binary_logloss: 0.248749\n",
      "[48]\ttrain's binary_logloss: 0.17332\tvalid's binary_logloss: 0.247716\n",
      "[49]\ttrain's binary_logloss: 0.171233\tvalid's binary_logloss: 0.247249\n",
      "[50]\ttrain's binary_logloss: 0.168808\tvalid's binary_logloss: 0.245712\n",
      "[51]\ttrain's binary_logloss: 0.166901\tvalid's binary_logloss: 0.244631\n",
      "[52]\ttrain's binary_logloss: 0.164701\tvalid's binary_logloss: 0.243459\n",
      "[53]\ttrain's binary_logloss: 0.162987\tvalid's binary_logloss: 0.242513\n",
      "[54]\ttrain's binary_logloss: 0.161101\tvalid's binary_logloss: 0.24179\n",
      "[55]\ttrain's binary_logloss: 0.159227\tvalid's binary_logloss: 0.240958\n",
      "[56]\ttrain's binary_logloss: 0.157179\tvalid's binary_logloss: 0.23982\n",
      "[57]\ttrain's binary_logloss: 0.155645\tvalid's binary_logloss: 0.239127\n",
      "[58]\ttrain's binary_logloss: 0.153637\tvalid's binary_logloss: 0.237746\n",
      "[59]\ttrain's binary_logloss: 0.152156\tvalid's binary_logloss: 0.237403\n",
      "[60]\ttrain's binary_logloss: 0.150492\tvalid's binary_logloss: 0.236752\n",
      "[61]\ttrain's binary_logloss: 0.14833\tvalid's binary_logloss: 0.235299\n",
      "[62]\ttrain's binary_logloss: 0.146708\tvalid's binary_logloss: 0.234711\n",
      "[63]\ttrain's binary_logloss: 0.145146\tvalid's binary_logloss: 0.234231\n",
      "[64]\ttrain's binary_logloss: 0.143475\tvalid's binary_logloss: 0.233571\n",
      "[65]\ttrain's binary_logloss: 0.141857\tvalid's binary_logloss: 0.233159\n",
      "[66]\ttrain's binary_logloss: 0.140617\tvalid's binary_logloss: 0.232806\n",
      "[67]\ttrain's binary_logloss: 0.139349\tvalid's binary_logloss: 0.232361\n",
      "[68]\ttrain's binary_logloss: 0.137656\tvalid's binary_logloss: 0.231805\n",
      "[69]\ttrain's binary_logloss: 0.13622\tvalid's binary_logloss: 0.231595\n",
      "[70]\ttrain's binary_logloss: 0.134909\tvalid's binary_logloss: 0.231123\n",
      "[71]\ttrain's binary_logloss: 0.133365\tvalid's binary_logloss: 0.23016\n",
      "[72]\ttrain's binary_logloss: 0.131928\tvalid's binary_logloss: 0.22954\n",
      "[73]\ttrain's binary_logloss: 0.130743\tvalid's binary_logloss: 0.2294\n",
      "[74]\ttrain's binary_logloss: 0.129119\tvalid's binary_logloss: 0.228424\n",
      "[75]\ttrain's binary_logloss: 0.127482\tvalid's binary_logloss: 0.227763\n",
      "[76]\ttrain's binary_logloss: 0.126147\tvalid's binary_logloss: 0.227717\n",
      "[77]\ttrain's binary_logloss: 0.124614\tvalid's binary_logloss: 0.226361\n",
      "[78]\ttrain's binary_logloss: 0.123468\tvalid's binary_logloss: 0.226123\n",
      "[79]\ttrain's binary_logloss: 0.121894\tvalid's binary_logloss: 0.224743\n",
      "[80]\ttrain's binary_logloss: 0.120732\tvalid's binary_logloss: 0.224614\n",
      "[81]\ttrain's binary_logloss: 0.119582\tvalid's binary_logloss: 0.224197\n",
      "[82]\ttrain's binary_logloss: 0.118468\tvalid's binary_logloss: 0.223638\n",
      "[83]\ttrain's binary_logloss: 0.117333\tvalid's binary_logloss: 0.223198\n",
      "[84]\ttrain's binary_logloss: 0.116301\tvalid's binary_logloss: 0.223096\n",
      "[85]\ttrain's binary_logloss: 0.11519\tvalid's binary_logloss: 0.222564\n",
      "[86]\ttrain's binary_logloss: 0.114083\tvalid's binary_logloss: 0.222174\n",
      "[87]\ttrain's binary_logloss: 0.112979\tvalid's binary_logloss: 0.222011\n",
      "[88]\ttrain's binary_logloss: 0.11165\tvalid's binary_logloss: 0.220694\n",
      "[89]\ttrain's binary_logloss: 0.110383\tvalid's binary_logloss: 0.220025\n",
      "[90]\ttrain's binary_logloss: 0.109327\tvalid's binary_logloss: 0.219546\n",
      "[91]\ttrain's binary_logloss: 0.108284\tvalid's binary_logloss: 0.218836\n",
      "[92]\ttrain's binary_logloss: 0.107136\tvalid's binary_logloss: 0.21845\n",
      "[93]\ttrain's binary_logloss: 0.106131\tvalid's binary_logloss: 0.218435\n",
      "[94]\ttrain's binary_logloss: 0.105149\tvalid's binary_logloss: 0.218246\n",
      "[95]\ttrain's binary_logloss: 0.104193\tvalid's binary_logloss: 0.218185\n",
      "[96]\ttrain's binary_logloss: 0.103162\tvalid's binary_logloss: 0.217907\n",
      "[97]\ttrain's binary_logloss: 0.102197\tvalid's binary_logloss: 0.217536\n",
      "[98]\ttrain's binary_logloss: 0.101254\tvalid's binary_logloss: 0.217335\n",
      "[99]\ttrain's binary_logloss: 0.100266\tvalid's binary_logloss: 0.217277\n",
      "[100]\ttrain's binary_logloss: 0.0994527\tvalid's binary_logloss: 0.217264\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "model.fit(tr_x, tr_y, va_x, va_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31132/2237417878.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mva_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mva_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mva_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mva_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mlog_loss\u001b[0;34m(y_true, y_pred, eps, normalize, sample_weight, labels)\u001b[0m\n\u001b[1;32m   2346\u001b[0m         \u001b[0mlb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2347\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2348\u001b[0;31m         \u001b[0mlb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2350\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mitself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \"\"\"\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_type_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"multioutput\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_type_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             raise ValueError(\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    323\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"f\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;31m# [.1, .2, 3] or [[.1, .2, 3]] or [[1., .2]] and not [1., 2., 3.]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"continuous\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    112\u001b[0m         ):\n\u001b[1;32m    113\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"infinity\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"NaN, infinity\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    115\u001b[0m                 msg_err.format(\n\u001b[1;32m    116\u001b[0m                     \u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "va_pred = model.perdict(va_x)\n",
    "score = log_loss(va_x,va_pred)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
