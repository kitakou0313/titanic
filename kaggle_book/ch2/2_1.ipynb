{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5531726674375732"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 回帰\n",
    "y_true = [1.0, 1.5, 2.0, 1.2, 1.8]\n",
    "y_pred = [0.8, 1.5, 1.8, 1.3, 3.0]\n",
    "\n",
    "rmse = np.sqrt(\n",
    "    mean_squared_error(y_true=y_true, y_pred=y_pred)\n",
    ")\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Root Mean Squad Error\n",
    "- 平均平方二乗誤差\n",
    "- 対応する真の値との差を二乗して平均を求め、平方を取ったもの\n",
    "- `誤差が正規分布に従うと仮定して最尤推定したときの最尤解と等しくなる`\n",
    "- 一つの代表値で誤差を最小化することを考えたとき、平均値が最小となる "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2値分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[3, 1],\n",
       "        [2, 2]]),\n",
       " array([[2, 1],\n",
       "        [2, 3]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 混同行列\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = np.array([1,0,1,1,0,1,1,0])\n",
    "y_pred = np.array([0,0,1,1,0,0,1,1])\n",
    "\n",
    "#tp...予測値を正例として、その予測が正しい場合 真陽性\n",
    "tp = np.sum((y_pred == 1) & (y_true == 1))\n",
    "#tn...予測値を負例として、予測が正しい場合 真陰性\n",
    "tn = np.sum((y_pred == 0) & (y_true == 0))\n",
    "\n",
    "#fp...予測値を正例として、予測が誤っている 偽陽性\n",
    "fp = np.sum((y_pred == 1) & (y_true == 0))\n",
    "#fm...予測値を負例として、予測が誤っている 偽陰性\n",
    "fn = np.sum((y_pred == 0) & (y_true == 1))\n",
    "\n",
    "cm1 = np.array(\n",
    "    [[tp, fp],\n",
    "    [tn, fn]\n",
    "    ]\n",
    ")\n",
    "\n",
    "cm2 = confusion_matrix(y_true, y_pred)\n",
    "cm1, cm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_true = [1,0,1,1,0,1,1,0]\n",
    "y_pred = [0,0,1,1,0,0,1,1]\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accurcy, Error rate\n",
    "- 正答率\n",
    "    - 予測が正しい割合\n",
    "    - (tp + tn) / (tp + tn + fp + fn)\n",
    "- 誤答率\n",
    "    - 1 - accuracy\n",
    "- 不均衡データに弱いのであまり使われないらしい\n",
    "    - 2値分類の場合は正例である予測確率を求めたあと閾値以上か以下かで分類する\n",
    "    - accuracyは50%\n",
    "    - `評価しているのはあるレコードが正例である確率を50%以上か以下かで振り分ける能力のみ`\n",
    "    - 10%以下、90%を正確に振り分ける能力を評価しているわけではない\n",
    "- 不均衡データの例\n",
    "    - 正例の割合が0.1%\n",
    "    - 正例である確率が5%の比較的高いレコードを予測したい\n",
    "        - 比較的は元のデータの正例の割合と比較しての意味っぽい\n",
    "    - accuが評価指標の場合、50%以下なのですべて負例\n",
    "        - 全レコードを負例とするモデルと変化なし\n",
    "    - 正しいモデルの評価が不可能になってしまう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.75, 0.6)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## precision, recall(適合率、再現率)\n",
    "from sklearn.metrics import precision_score ,recall_score\n",
    "\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "\n",
    "precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RrecisionとRecall\n",
    "- Precision...適合率\n",
    "    - TP / (TP + FP)\n",
    "    - 正例としたものの内どれだけの値が正しいか\n",
    "- Recall...再現率、感度\n",
    "    - TP / (TP + FN)\n",
    "    - 真の値が正例の内どれだけ正例と予測できるか\n",
    "- トレードオフの関係になっている\n",
    "    - Precisionを上げたい...\n",
    "    - FPを減らすために負例の閾値を下げよう！\n",
    "    - FNの増加 -> Recallが低下\n",
    "- 二つセットで使用する\n",
    "    - 誤検知を減らしたい -> presicionを重視\n",
    "    - 正例の見逃しを避けたい -> Recallを重視\n",
    "\n",
    "\n",
    "## MCC\n",
    "- 正例データの割合が不均衡なときに使用される指標\n",
    "- 正例、負例を対等に扱う\n",
    "    - F1は正例のみに注目した指標なので、入れ替えると振る舞いが変化\n",
    "\n",
    "\n",
    "## F1, MCCが対象のコンペ\n",
    "- これらが最大化されるよう閾値を設定する必要がある\n",
    "    - 閾値で値が変化してしまう\n",
    "- 特性を考えて使用していこう "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6666666666666665, 0.625)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# F1-score, Fβ-score\n",
    "from sklearn.metrics import f1_score, fbeta_score\n",
    "\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "fbeta = fbeta_score(y_true=y_true, y_pred=y_pred, beta=2)\n",
    "\n",
    "f1, fbeta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## f1とf score\n",
    "- F値ってやつ\n",
    "- PresicionとRecallの調和平均\n",
    "    - aとbの調和平均 n = 2の時\n",
    "    - n / (1/a + 1/b)\n",
    "    - 全体として着目している数量が同じものに対して適切な平均\n",
    "    - 今回ではTPが分子で等しいため使用している\n",
    "    - https://www.cresco.co.jp/blog/entry/10325/\n",
    "    - 通常の平均と変わらないそんなには変わらない\n",
    "        - 平均を取る値の全体の内着目してる部分の違い\n",
    "        - 食塩の量が同じ(cグラム)で水の量が違う(a,b)食塩水を混ぜたときの食塩水はc/((a + b)/2)\n",
    "- f1\n",
    "    - 2 / {(1 / recall) + (1 / precision)}\n",
    "    - 2TP / {2TP + FP + FN}\n",
    "- fbeteはRecallの重要度をbetaで重みづけできる指標\n",
    "    - beteが大きいほどRecallが重視される\n",
    "    - f2などの形で用いられる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7135581778200728"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logloss(cross entoropy)\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "y_true = [1,0,1,1,0,1]\n",
    "y_pred = [0.1, 0.2, 0.8,0.8,0.1,0.3]\n",
    "\n",
    "logloss = log_loss(y_true=y_true, y_pred=y_pred)\n",
    "logloss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Loss(cross entropy)\n",
    "- 正例である確率を評価値とする場合\n",
    "- Cross Entropy\n",
    "    - logloss = 1/N Σ_{1..N}(y_i(log(p_i)) + (1-y_i)log(1-p_i))\n",
    "    - y_i...1 or 0 正解\n",
    "    - p_i...0~1 予測された確率値\n",
    "    - log関数は0...-inf , 1...0と変化するので、予測確率値がy_iに近いほど0に近くなるよう定義されている\n",
    "    - p_iで微分するとp_i == y_iの時最小\n",
    "        - 確率を正確に予測できているとき最小\n",
    "        - ラベルが確率的に与えられていると考えると確率と見なせる（データ生成時に確率的にラベルが降られている）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8125"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AUC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "y_true = [1,0,1,1,0,1]\n",
    "y_pred = [0.1, 0.2, 0.8,0.8,0.1,0.3]\n",
    "\n",
    "auc = roc_auc_score(y_true=y_true, y_score=y_pred)\n",
    "auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUC\n",
    "- 偽陽性、真陽性率を(x, y)として、陽性の閾値を徐々に低くしていったときに描かれた曲線（ROC曲線...reciever Operating Charactaristic Curve）の下部の面積\n",
    "- Gini係数と線形の関係\n",
    "    - 2*AUC-1\n",
    "- 正例と負例をランダムに選んだ時に正例の予測値が負例の予測値よりも大きい確率 として定義できる\n",
    "    - {y_i = 1, y_j = 0, ^y_i > ^y_j を満たすi, jの組数} / {y_i = 1, y_j = 0を満たす組数}\n",
    "- 各レコードの予測値の大小関係のみが値に影響する\n",
    "    - そのため予測値は確率でなくても問題なし"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多クラス分類での評価指標"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3625557672904274"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mutli class log loss\n",
    "from sklearn.metrics import log_loss\n",
    "y_true = np.array([0, 2, 1, 2, 2])\n",
    "y_pred = np.array(\n",
    "    [[0.68, 0.32, 0.00],\n",
    "    [0.00, 0.00, 1.00],\n",
    "    [0.60, 0.40, 0.00],\n",
    "    [0.00, 0.00, 1.00],\n",
    "    [0.28, 0.12, 0.60]]\n",
    ")\n",
    "logloss = log_loss(y_true, y_pred)\n",
    "logloss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass logloss\n",
    "- LogLossの多クラスへの拡張\n",
    "    - Nレコード、Mクラス\n",
    "    - LogLoss = -1/N Σ_N Σ_M y_n_m log p_n_m\n",
    "    - 割り当てられたクラスへの予測確率が低いほど大きくなる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5933333333333334"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## mean_f1\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "y_true = np.array([\n",
    "    [1,1,0],\n",
    "    [1,0,0],\n",
    "    [1,1,1],\n",
    "    [0,1,1],\n",
    "    [0,0,1]\n",
    "])\n",
    "\n",
    "y_pred = np.array([\n",
    "    [1, 0, 1],\n",
    "    [0, 1, 0],\n",
    "    [1, 0, 1],\n",
    "    [0, 0, 1],\n",
    "    [0, 0, 1]]\n",
    ")\n",
    "\n",
    "# mean f1はレコード毎にF1スコアを計算\n",
    "mean_f1 = np.mean(\n",
    "    [f1_score(y_true[i, :], y_pred[1,:]) for i in range(len(y_true))]\n",
    ")\n",
    "\n",
    "n_class = len(y_true[0])\n",
    "# macroはクラスごとにF1スコアを計算\n",
    "# 各クラスごとに2値分分類してるのと同じ\n",
    "# クラスごとに閾値の最適化が可能\n",
    "macro_f1 = np.mean(\n",
    "    [f1_score(y_pred=y_pred[:, c], y_true=y_true[:, c]) for c in range(n_class)]\n",
    ")\n",
    "\n",
    "# レコード*クラスのペア度とにTP/TN/FP/FNを計算し、F1-scoreを求める\n",
    "micro_f1 = f1_score(y_true.reshape(-1), y_pred.reshape(-1))\n",
    "mean_f1, macro_f1, micro_f1\n",
    "\n",
    "mean_f1 = f1_score(y_pred=y_pred, y_true=y_true, average=\"samples\")\n",
    "mean_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9428571428571428, 0.6153846153846154)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## クラス間に順序関係があるときのマルチクラス分類\n",
    "## quandratic weighted kappa\n",
    "from sklearn.metrics import confusion_matrix, cohen_kappa_score\n",
    "y_true = [1, 2, 3, 4, 3]\n",
    "y_pred = [2, 2, 4, 4, 5]\n",
    "\n",
    "def quadratic_weighted_kappa(c_matrix:np.array):\n",
    "    \"\"\"\n",
    "    quadratic_weighted_kappaの計算\n",
    "    \"\"\"\n",
    "    numer = 0\n",
    "    denom = 0\n",
    "\n",
    "    n = c_matrix.shape[0]\n",
    "    for i in range(c_matrix.shape[0]):\n",
    "        for j in range(c_matrix.shape[1]):\n",
    "            \n",
    "            wij = ((i-j) ** 2)\n",
    "            oij = c_matrix[i, j]\n",
    "            eij = (c_matrix[i, :].sum() * c_matrix[:, j].sum()) / c_matrix.sum()\n",
    "\n",
    "            numer += wij * oij\n",
    "            denom += wij + eij\n",
    "\n",
    "\n",
    "    return 1 - numer / denom\n",
    "\n",
    "c_matrix = confusion_matrix(y_true, y_pred, labels=[1,2,3,4,5])\n",
    "quadratic_weighted_kappa(c_matrix), cohen_kappa_score(y_true, y_pred, weights=\"quadratic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## quandratic weighted kappa\n",
    "- 完全な予測の場合1, ランダム予測で0, ランダムより悪化で0未満"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
